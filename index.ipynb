{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Logistic Regression Models - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "As we saw with KNN, we need alternative evaluation metrics to determine the effectiveness of classification algorithms. In regression, we were predicting values so it made sense to discuss error as a distance of how far off our estimates were. In classifying a binary variable however, we are either correct or incorrect. As a result, we tend to deconstruct this as how many false positives versus false negatives we come across.  \n",
    "In particular, we examine a few different specific measurements when evaluating the performance of a classification algorithm. In this review lab, we'll review precision, recall and accuracy in order to evaluate our logistic regression models.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "You will be able to:  \n",
    "* Understand and assess precision recall and accuracy of classifiers\n",
    "* Evaluate classification models using various metrics\n",
    "\n",
    "## Terminology Review  \n",
    "\n",
    "Let's take a moment and review some classification evaluation metrics:  \n",
    "\n",
    "\n",
    "$Precision = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}}$    \n",
    "  \n",
    "\n",
    "$Recall = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}}$  \n",
    "  \n",
    "$Accuracy = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}}$\n",
    "\n",
    "![](./images/Precisionrecall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, we may wish to tune a classification algorithm to optimize against precison or recall rather then overall accuracy. For example, imagine the scenario of predicting whether or not a patient is at risk for cancer and should be brought in for additional testing. In cases such as this, we often may want to cast a slightly wider net, and it is much preferable to optimize for recall, the number of cancer positive cases, then it is to optimize precision, the percentage of our predicted cancer-risk patients who are indeed positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a standard logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = LogisticRegression(fit_intercept=False, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a function to calculate the precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_hat, y):\n",
    "    y_yhat = list(zip(y,y_hat))\n",
    "    tp = sum([1 for y, yh in y_yhat if y==1 and yh==1])     # Num of True positives\n",
    "    fp = sum([1 for y, yh in y_yhat if y==0 and yh==1])  # Num of False positives\n",
    "    numer = tp\n",
    "    denom = tp + fp # num of all predicted positives\n",
    "    return numer / denom\n",
    "    #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a function to calculate the recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_hat, y):\n",
    "    y_yhat = list(zip(y,y_hat))\n",
    "    tp = sum([1 for y, yh in y_yhat if y==1 and yh==1] )\n",
    "    fn = sum([1 for y, yh in y_yhat if y==1 and yh==0])    \n",
    "    numer = tp     # Num of True positives\n",
    "    denom = tp + fn       # Num of Actual positives\n",
    "    return numer / denom\n",
    "    #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write a function to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    y_yhat = list(zip(y,y_hat))\n",
    "\n",
    "    tp = sum([1 for y, yh in y_yhat if y==1 and yh==1])\n",
    "    tn = sum([1 for y, yh in y_yhat if y==0 and yh==0])\n",
    "    numer = tp + tn     # Num of True positives + True Negatives\n",
    "    denom = len(y)     # Num of ALL observations\n",
    "    return numer / denom\n",
    "    #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate the precision, recall and accuracy of your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train stats: precision 0.8345864661654135\n",
      "test stats: precision 0.8125 \n",
      "\n",
      "train stats: recall 0.9098360655737705\n",
      "test stats: recall 0.9069767441860465 \n",
      "\n",
      "train stats: accuracy 0.8546255506607929\n",
      "test stats: accuracy 0.8289473684210527 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "y_hat_train = logit_model.predict(X_train)\n",
    "y_hat_test = logit_model.predict(X_test)\n",
    "for fn in [precision, recall, accuracy]:\n",
    "    print('train stats:',fn.__name__, fn(y_hat_train, y_train))\n",
    "    print('test stats:',fn.__name__,fn(y_hat_test, y_test),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing Precision Recall and Accuracy of Test vs Train Sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the precision, recall and accuracy for test and train splits using different train set sizes. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Precision = []\n",
    "testing_Precision = []\n",
    "training_Recall = []\n",
    "testing_Recall = []\n",
    "training_Accuracy = []\n",
    "testing_Accuracy = []\n",
    "\n",
    "for i in range(10,95):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= i/100) #replace the \"None\" here\n",
    "    logreg = LogisticRegression(fit_intercept = False, C = 1e12, solver='liblinear', max_iter=1000)\n",
    "    model_log = logreg.fit(X_train, y_train)\n",
    "    y_hat_test = model_log.predict(X_test)\n",
    "    y_hat_train = model_log.predict(X_train)\n",
    "    training_Precision.append(precision(y_hat_train, y_train))\n",
    "    testing_Precision.append(precision(y_hat_test, y_test))\n",
    "    training_Recall.append(recall(y_hat_train, y_train))\n",
    "    testing_Recall.append(recall(y_hat_test, y_test))\n",
    "    training_Accuracy.append(accuracy(y_hat_train, y_train))\n",
    "    testing_Accuracy.append(accuracy(y_hat_test, y_test))  \n",
    "\n",
    "# 6 lines of code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 scatter plots looking at the test and train precision in the first one, test and train recall in the second one, and testing and training accuracy in the third one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6ebdcac7f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code for test and train precision\n",
    "plt.style.use('dark_background')\n",
    "plt.scatter(range(len(training_Accuracy)), training_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test and train recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test and train accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Nice! In this lab, you gained some extra practice with evaluation metrics for classification algorithms. You also got some further python practice by manually coding these functions yourself, giving you a deeper understanding of how they work. Going forward, continue to think about scenarios in which you might prefer to optimize one of these metrics over another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
